% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{TUTDatatbase}
A.~Mesaros, T.~Heittola, and T.~Virtanen, ``{TUT} database for acoustic scene
  classification and sound event detection,'' in \emph{Proceedings of
  {EUSIPCO}}, 2016, pp. 1128--1132.

\bibitem{sed1}
Y.~Chen, H.~Dinkel, M.~Wu, and K.~Yu, ``Voice activity detection in the wild
  via weakly supervised sound event detection,'' in \emph{Proceedings of
  {Interspeech}}, H.~Meng, B.~Xu, and T.~F. Zheng, Eds.\hskip 1em plus 0.5em
  minus 0.4em\relax {ISCA}, 2020, pp. 3665--3669.

\bibitem{sed2}
S.~G. Upadhyay, B.~Su, and C.~Lee, ``Attentive convolutional recurrent neural
  network using phoneme-level acoustic representation for rare sound event
  detection,'' in \emph{Proceedings of {Interspeech}}, H.~Meng, B.~Xu, and
  T.~F. Zheng, Eds.\hskip 1em plus 0.5em minus 0.4em\relax {ISCA}, 2020, pp.
  3102--3106.

\bibitem{se}
W.~Xia and K.~Koishida, ``{Sound Event Detection in Multichannel Audio Using
  Convolutional Time-Frequency-Channel Squeeze and Excitation},'' in
  \emph{Proc. Interspeech 2019}, 2019, pp. 3629--3633.

\bibitem{su2017weakly}
T.-W. Su, J.-Y. Liu, and Y.-H. Yang, ``Weakly-supervised audio event detection
  using event-specific gaussian filters and fully convolutional networks,'' in
  \emph{Proceedings of {ICASSP}}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2017, pp. 791--795.

\bibitem{pert}
X.~Zheng, Y.~Song, J.~Yan, L.-R. Dai, I.~McLoughlin, and L.~Liu, ``{An
  Effective Perturbation Based Semi-Supervised Learning Method for Sound Event
  Detection},'' in \emph{Proc. Interspeech 2020}, 2020, pp. 841--845.

\bibitem{tf}
Y.-H. Shen, K.-X. He, and W.-Q. Zhang, ``{Learning How to Listen: A
  Temporal-Frequential Attention Model for Sound Event Detection},'' in
  \emph{Proc. Interspeech 2019}, 2019, pp. 2563--2567.

\bibitem{autoTagging}
J.~Liu and Y.~Yang, ``Event localization in music auto-tagging,'' in
  \emph{Proceedings of {ACMMM}}, 2016, pp. 1048--1057.

\bibitem{audiofew}
J.~Pons, J.~Serr{\`{a}}, and X.~Serra, ``Training neural audio classifiers with
  few data,'' in \emph{Proceedings of {ICASSP}}.\hskip 1em plus 0.5em minus
  0.4em\relax {IEEE}, 2019, pp. 16--20.

\bibitem{song}
H.~Song, J.~Han, S.~Deng, and Z.~Du, ``{Acoustic Scene Classification by
  Implicitly Identifying Distinct Sound Events},'' in \emph{Proc. Interspeech
  2019}, 2019, pp. 3860--3864.

\bibitem{park}
I.~Park and H.~K. Kim, ``{Two-Stage Polyphonic Sound Event Detection Based on
  Faster R-CNN-LSTM with Multi-Token Connectionist Temporal Classification},''
  in \emph{Proc. Interspeech 2020}, 2020, pp. 856--860.

\bibitem{few-shot-sound-detection}
Y.~Wang, J.~Salamon, N.~J. Bryan, and J.~P. Bello, ``Few-shot sound event
  detection,'' in \emph{Proceedings of {ICASSP}}.\hskip 1em plus 0.5em minus
  0.4em\relax {IEEE}, 2020, pp. 81--85.

\bibitem{attentionSimilarity}
S.~Chou, K.~Cheng, J.~R. Jang, and Y.~Yang, ``Learning to match transient sound
  events using attentional similarity for few-shot sound recognition,'' in
  \emph{Proceedings of {ICASSP}}, 2019, pp. 26--30.

\bibitem{rare}
W.~Wang, C.-C. Kao, and C.~Wang, ``A simple model for detection of rare sound
  events,'' in \emph{Proc. Interspeech 2018}, 2018, pp. 1344--1348.

\bibitem{few-att-gnn}
S.~Zhang, Y.~Qin, K.~Sun, and Y.~Lin, ``Few-shot audio classification with
  attentional graph neural networks,'' in \emph{Proceedings of {Interspeech}},
  G.~Kubin and Z.~Kacic, Eds.\hskip 1em plus 0.5em minus 0.4em\relax {ISCA},
  2019, pp. 3649--3653.

\bibitem{fewShotGNN}
V.~G. Satorras and J.~B. Estrach, ``Few-shot learning with graph neural
  networks,'' in \emph{Proceedings of {ICLR}}, 2018.

\bibitem{TPN}
Y.~Liu, J.~Lee, M.~Park, S.~Kim, E.~Yang, S.~J. Hwang, and Y.~Yang, ``Learning
  to propagate labels: Transductive propagation network for few-shot
  learning,'' in \emph{Proceedings of {ICLR}}, 2019.

\bibitem{MatchNet}
O.~Vinyals, C.~Blundell, T.~Lillicrap, K.~Kavukcuoglu, and D.~Wierstra,
  ``Matching networks for one shot learning,'' in \emph{Proceedings of {NIPS}},
  2016, pp. 3630--3638.

\bibitem{protoNet}
J.~Snell, K.~Swersky, and R.~S. Zemel, ``Prototypical networks for few-shot
  learning,'' in \emph{Proceedings of {NIPS}}, 2017, pp. 4077--4087.

\bibitem{relationNet}
F.~Sung, Y.~Yang, L.~Zhang, T.~Xiang, P.~H.~S. Torr, and T.~M. Hospedales,
  ``Learning to compare: Relation network for few-shot learning,'' in
  \emph{Proceedings of {CVPR}}, 2018, pp. 1199--1208.

\bibitem{CloserLook}
W.~Chen, Y.~Liu, Z.~Kira, Y.~F. Wang, and J.~Huang, ``A closer look at few-shot
  classification,'' in \emph{Proceedings of {ICLR}}.\hskip 1em plus 0.5em minus
  0.4em\relax OpenReview.net, 2019.

\bibitem{fewgnn}
V.~G. Satorras and J.~B. Estrach, ``Few-shot learning with graph neural
  networks,'' in \emph{Proceedings of {ICLR}}.\hskip 1em plus 0.5em minus
  0.4em\relax OpenReview.net, 2018.

\bibitem{maml}
C.~Finn, P.~Abbeel, and S.~Levine, ``Model-agnostic meta-learning for fast
  adaptation of deep networks,'' in \emph{Proceedings of {ICML}}, 2017, pp.
  1126--1135.

\bibitem{opt1}
S.~Ravi and H.~Larochelle, ``Optimization as a model for few-shot learning,''
  in \emph{Proceedings of {ICLR}}.\hskip 1em plus 0.5em minus 0.4em\relax
  OpenReview.net, 2017.

\bibitem{opt2}
A.~Nichol, J.~Achiam, and J.~Schulman, ``On first-order meta-learning
  algorithms,'' \emph{CoRR}, vol. abs/1803.02999, 2018.

\bibitem{koch2015siamese}
G.~Koch, R.~Zemel, and R.~Salakhutdinov, ``Siamese neural networks for one-shot
  image recognition,'' in \emph{ICML deep learning workshop}, vol.~2, 2015.

\bibitem{TSVM}
T.~Joachims, ``Transductive inference for text classification using support
  vector machines,'' in \emph{Proceedings of {ICML}}, 1999, pp. 200--209.

\bibitem{TPNzero}
Y.~Fu, T.~M. Hospedales, T.~Xiang, and S.~Gong, ``Transductive multi-view
  zero-shot learning,'' \emph{{IEEE} Trans. PAMI.}, vol.~37, no.~11, pp.
  2332--2345, 2015.

\bibitem{timefrequnencymask}
D.~S. Park, W.~Chan, Y.~Zhang, C.~Chiu, B.~Zoph, E.~D. Cubuk, and Q.~V. Le,
  ``Specaugment: {A} simple data augmentation method for automatic speech
  recognition,'' in \emph{Proceedings of {Interspeech}}.\hskip 1em plus 0.5em
  minus 0.4em\relax {ISCA}, 2019, pp. 2613--2617.

\bibitem{dataa}
Y.~Chen and H.~Jin, ``{Rare Sound Event Detection Using Deep Learning and Data
  Augmentation},'' in \emph{Proc. Interspeech 2019}, 2019, pp. 619--623.

\bibitem{ESC_dataset_50}
K.~J. Piczak, ``{ESC:} dataset for environmental sound classification,'' in
  \emph{Proceedings of {ACMMM}}, 2015, pp. 1015--1018.

\bibitem{librosa}
P.~Raguraman, M.~Ramasundaram, and M.~Vijayan, ``Librosa based assessment tool
  for music information retrieval systems,'' in \emph{Proceedings of {MIPR}},
  2019, pp. 109--114.

\bibitem{SimilairtyEmbeddingNetwork}
Y.~Huang, S.~Chou, and Y.~Yang, ``Generating music medleys via playing music
  puzzle games,'' in \emph{Proceedings of {AAAI}}, 2018, pp. 2281--2288.

\bibitem{dataaug}
X.~Song, Z.~Wu, Y.~Huang, D.~Su, and H.~Meng, ``Specswap: {A} simple data
  augmentation method for end-to-end speech recognition,'' in \emph{Proceedings
  of {Interspeech}}, H.~Meng, B.~Xu, and T.~F. Zheng, Eds.\hskip 1em plus 0.5em
  minus 0.4em\relax {ISCA}, 2020, pp. 581--585.

\bibitem{fewshotdomain}
B.~Shi, M.~Sun, K.~C. Puvvada, C.~Kao, S.~Matsoukas, and C.~Wang, ``Few-shot
  acoustic event detection via meta-learning,'' in \emph{Proceedings of
  {ICASSP}}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 76--80.

\bibitem{domainad}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~S. Lempitsky, ``Domain-adversarial training of neural
  networks,'' in \emph{Domain Adaptation in Computer Vision Applications}, ser.
  Advances in CVPR, G.~Csurka, Ed.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2017, pp. 189--209.

\bibitem{domain_ad}
S.~Motiian, Q.~Jones, S.~M. Iranmanesh, and G.~Doretto, ``Few-shot adversarial
  domain adaptation,'' in \emph{Proceedings of {NeurIPS}}, I.~Guyon, U.~von
  Luxburg, S.~Bengio, H.~M. Wallach, R.~Fergus, S.~V.~N. Vishwanathan, and
  R.~Garnett, Eds., 2017, pp. 6670--6680.

\bibitem{audioSet}
J.~F. Gemmeke, D.~P.~W. Ellis, D.~Freedman, A.~Jansen, W.~Lawrence, R.~C.
  Moore, M.~Plakal, and M.~Ritter, ``Audio set: An ontology and human-labeled
  dataset for audio events,'' in \emph{Proceedings of {ICASSP}}, 2017, pp.
  776--780.

\end{thebibliography}
