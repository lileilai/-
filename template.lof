\contentsline {figure}{\numberline {1}{\ignorespaces An example illustrates the motivation. (a) defines five classes(c1-c5), each class contains 1 example. Thereâ€™re three feature dimensions: \textit {Tone}, \textit {Timbre} and \textit {loudness}. Different color means different value of the feature, same color adds the similarity score by 1; (b) In the k-shot(k=3) setting, all examples of class c3 share the same value in dimension \textit {Tone} even though their \textit {Timbre} and \textit {loudness} are different. \relax }}{2}%
\contentsline {figure}{\numberline {2}{\ignorespaces (a).The overall framework of our model, it is composed of three parts: feature encoder, task-aware Module and metric-based few-shot learning network. (b).The temporal\&channel attention mechanism. $A_{ch}$ is the channel attention, $A_{te}$ is temporal attention. (c).Data augmentation pipeline for the input log mel-spectrogram.\relax }}{3}%
\contentsline {figure}{\numberline {3}{\ignorespaces 5-way performance with various training/test shots\relax }}{5}%
